\chapter{Solver implementations}
    In this chapter we'll discuss various implementation aspects of the \emph{ab
    initio} solvers discussed in \autoref{chap:hf} through \autoref{chap:ci} and
    \autoref{chap:cc}.

    \section{Hartree-Fock}
        In \autoref{sec:hf} we showed how the variational principle of the
        Hartree-Fock ansatz led to the canonical Hartree-Fock equations, where
        the molecular orbitals are the primary unknowns.
        Here we will demonstrate how we can find solvable equations for the
        molecular orbitals starting from an initial basis of atomic orbitals.
        We will in the following demonstrate three different procedures related
        to the restrictions put on the spin-orbitals as discussed in
        \autoref{subsec:restrictions-on-spin-orbitals}.
        First we'll discuss a general Hartree-Fock method which puts no
        restrictions on the molecular orbitals.
        This method leads to the molecular orbitals being described as general
        spin-orbitals as shown in \autoref{eq:general-spin-orbital}.
        The second method is known as the \emph{restricted Hartree-Fock} method
        as it limits the molecuar orbitals to restricted spin-orbitals as
        discussed in \autoref{eq:restricted-spin-orbital}.
        Finally, we'll demonstrate the \emph{unrestricted Hartree-Fock method}
        yielding unrestricted spin-orbitals for the molecular orbitals as
        shown in \autoref{eq:unrestricted-spin-orbital}.

        \subsection{Hartree-Fock with general spin-orbitals}
            \label{subsec:ghf}
            Given a known atomic orbital basis, e.g., harmonic oscillator basis,
            $\brac{\chi_{\alpha}}_{\alpha = 1}^{K}$ we wish to find an
            orthonomal basis of molecular orbitals $\brac{\phi_{p}}_{p = 1}^{L}$
            satisfying the canonical Hartree-Fock equations.
            We can transform from the known atomic orbital basis to the unknown
            molecular orbital basis by
            \begin{align}
                \ket{\phi_p} = C_{\alpha p}\ket{\chi_{\alpha}},
            \end{align}
            where $\vfg{C} \in \mathbb{C}^{K\times L}$ is now our unknown
            coefficient matrix.
            The orthonormality condition of the molecular orbitals can now be
            formulated as
            \begin{align}
                \braket{\phi_p}{\phi_q}
                &= C^{*}_{\alpha p} C_{\beta q}
                \braket{\chi_{\alpha}}{\chi_{\beta}}
                = C^{*}_{\alpha p} \overlapten_{\alpha \beta}
                C_{\beta q}
                = \delta_{pq},
            \end{align}
            where $\overlapten_{\alpha\beta}$ is the matrix elements of the
            overlap matrix $\overlapmat \in \mathbb{C}^{K\times K}$ of the
            atomic orbitals.
            By left-projecting with a state from our atomic orbital basis onto
            the canonical Hartree-Fock equations, we obtain
            \begin{gather}
                \mel{\chi_{\alpha}}{\fock}{\phi_q}
                = \epsilon_{q} \braket{\chi_{\alpha}}{\phi_q}
                \implies
                \mel{\chi_{\alpha}}{\fock}{\chi_{\beta}} C_{\beta q}
                = \epsilon_q C_{\beta q} \overlapten_{\alpha \beta}.
            \end{gather}
            We denote the matrix elements of the Fock operator in the atomic
            orbital basis by
            \begin{align}
                \mel{\chi_{\alpha}}{\fock}{\chi_{\beta}}
                \equiv \fockten_{\alpha \beta}.
                \label{eq:ghf-fock-mel}
            \end{align}
            In the case of an orthonormal basis of atomic orbitals, the overlap
            matrix $\overlapmat \in \mathbb{C}^{K \times K}$ reduces to the identity
            matrix.
            The projected Hartree-Fock equations can then be written
            \begin{gather}
                \fockten_{\alpha\beta} C_{\beta q}
                = \overlapten_{\alpha \beta} C_{\beta q} \epsilon_{q}
                \implies
                \fockmat \vfg{C} = \overlapmat \vfg{C} \vfg{\epsilon},
                \label{eq:roothan-hall-general}
            \end{gather}
            where $\fockmat \in \mathbb{C}^{K \times K}$ is the \emph{Fock
            matrix} consisting of the matrix elements defined in
            \autoref{eq:ghf-fock-mel}.
            The diagonal matrix $\vfg{\epsilon} = \diag(\epsilon_1, \dots,
            \epsilon_L)$ is the matrix with the orbital eigenenergies from the
            canonical Hartree-Fock equation.
            The orbital eigenenergies are indeed energies, but they are
            \emph{not} the eigenenergy of the total Hamiltonian.
            Rather they are similar to the eigenergies of the one-body
            Hamiltonian, but with a the Fock operator representing a one-body
            Hamiltonian containing a potential built from the mean-field
            interaction in the many-body problem.
            % TODO: Double check these sentences.
            The equations in \autoref{eq:roothan-hall-general} are known as the
            \emph{Roothan-Hall} equations \cite{roothan, hall}.
            The Roothan-Hall equations constitute a generalized eigenvalue
            equation.\footnote{%
                The grammar sounds highly speculative as we talk about the
                Roothan-Hall \emph{equations} reducing to a single
                \emph{equation}.
            }
            % TODO: Check the grammar!
            These equations represent a computational improvement to the
            integro-differential equations that come from the canonical
            Hartree-Fock equations.

            In Python we solve the Roothan-Hall equations using SymPy's linear
            algebra routine \pyth{scipy.linalg.eigh} which solves both ordinary
            and generalized eigenvalue equations for symmetric and Hermitian
            matrices \cite{sympy}, viz.
            \begin{python}
epsilon, C = scipy.linalg.eigh(fock_matrix, s)
            \end{python}
            where \pyth{s} is the overlap matrix.
            Our solution does not discriminate whether the atomic orbitals are
            orthornomal or not.
            We always solve the generalized eigenvalue equation, and therefore
            pass in the idenity matrix as the overlap matrix in case of an
            orthonormal atomic orbital basis.

        \subsection{Constructing the general Fock matrix}
            An important point to note is that the Fock matrix elements depends
            on both the atomic and the molecular orbitals.
            That is,
            \begin{align}
                \fockten_{\alpha\beta}
                &= \mel{\chi_{\alpha}}{\fock}{\chi_{\beta}}
                = \mel{\chi_{\alpha}}{\onehamil}{\chi_{\beta}}
                +
                \mel{\chi_{\alpha}\phi_j}{\twohamil}{\chi_{\beta}\phi_j}_{AS},
            \end{align}
            where $j$ only sums over the occupied indices.
            We notice that only the antisymmetric two-body elements depend on
            the molecular orbitals.
            Formulating the matrix elements in terms of he known atomic orbitals
            and the coefficient matrix we get
            \begin{align}
                \mel{\chi_{\alpha}\phi_j}{\twohamil}{\chi_{\beta}\phi_j}
                &=
                C^{*}_{\gamma j} C_{\delta j}
                \mel{\chi_{\alpha}\chi_{\gamma}}{\twohamil}{\chi_{\beta}\chi_{\delta}},
                \\
                \mel{\chi_{\alpha}\phi_j}{\twohamil}{\phi_j\chi_{\beta}}
                &=
                C^{*}_{\gamma j} C_{\delta j}
                \mel{\chi_{\alpha}\chi_{\gamma}}{\twohamil}{\chi_{\delta}\chi_{\beta}}.
            \end{align}
            The product of the coefficient matrices inspires the introduction of
            the density matrix of the occupied orbitals
            \begin{align}
                D_{\delta\gamma} \equiv
                C^{*}_{\gamma j} C_{\delta j}
                \implies
                \vfg{D} = \vfg{C}_{o}\vfg{C}^{\dagger}_{o},
                \label{eq:ghf-density-matrix}
            \end{align}
            where $\vfg{D} \in \mathbb{C}^{K \times K}$, and we've denoted the
            occupied coefficient matrices by $\vfg{C}_o \in \mathbb{C}^{K \times
            N}$.
            We can compute the density matrix in Python by
            \begin{python}
o = slice(0, n)
density_matrix = C[:, o] @ C[:, 0].conj().T
            \end{python}
            where \pyth{n} is he number of occupied particles and \pyth{o} is a
            slice with the indices of the occupied states.
            We can then write the matrix elements of the Fock operator in terms
            of the atomic orbitals and the density matrix as
            \begin{align}
                \fockten_{\alpha\beta}
                &= \mel{\chi_{\alpha}}{\onehamil}{\chi_{\beta}}
                +
                D_{\delta\gamma}
                \mel{\chi_{\alpha}\chi_{\gamma}}{\twohamil}{\chi_{\beta}\chi_{\delta}}_{AS}.
                \label{eq:ghf-fock-matrix}
            \end{align}
            We use NumPy's tensor contraction routine \pyth{np.tensordot} to
            contract the density matrix and the two-body antisymmetric matrix.
            The Fock matrix can thus be constructed by
            \begin{python}
fock_matrix = (
    h + np.tensordot(density_matrix, u, axes=((0, 1), (3, 1)))
)
            \end{python}
            where \pyth{h} is the one-body matrix elements, \pyth{u} the
            antisymmetric two-body elements with the memory ordered by reading
            the indices from left to right, and \pyth{density_matrix} the
            density matrix.

            \subsubsection{General Hartree-Fock energy}
                The Hartree-Fock energy can be found by inserting the expansion
                of the molecular orbitals in terms of the atomic orbitals and
                the coefficient matrices into the energy functional from
                \autoref{eq:energy_func_hf}.
                This yields
                \begin{align}
                    \energy
                    &= \mel{\phi_i}{\onehamil}{\phi_i}
                    + \half\mel{\phi_i\phi_j}{\twohamil}{\phi_i\phi_j}_{AS}
                    \\
                    &=
                    D_{\beta\alpha}
                    \mel{\chi_{\alpha}}{\onehamil}{\chi_{\beta}}
                    + \half
                    D_{\gamma\alpha} D_{\delta\beta}
                    \mel{\chi_{\alpha}\chi_{\beta}}{
                        \twohamil
                    }{\chi_{\gamma}\chi_{\delta}}_{AS},
                    \label{eq:general-hartree-fock-energy}
                \end{align}
                where we've contracted the occupied coefficient matrices into
                density matrices.
                In Python we compute energy by
                \begin{python}
energy = np.trace(np.dot(density_matrix, h))
term = 0.5 * np.tensordot(
    density_matrix, u, axes=((0, 1), (2, 0))
)
energy += np.trace(np.dot(density_matrix, term))
                \end{python}
                where \pyth{term} is used as a temporary storage for the
                contraction of one of the density matrices with the
                antisymmetric two-body elements.

            \subsubsection{General Hartree-Fock one-body density matrix}
                The one-body density matrix elements is given by
                \begin{align}
                    \densityten^{q}_{p}
                    = \braslat
                    \ccr{p}
                    \can{q}
                    \ketslat
                    = \delta_{p \in o}
                    C^{*}_{\alpha p} \overlapten_{\alpha\beta}
                    C_{\beta q}
                    = \delta_{p \in o}
                    \delta_{pq},
                \end{align}
                where we have labelled the set of occupied indices in the Slater
                determinants by $o = \brac{1, \dots N}$.
                We can represent the one-body density matrix as a block matrix
                by
                \begin{align}
                    \vfg{\densityten}
                    = \begin{pmatrix}
                        \1_{N \times N} & \vfg{0}_{N \times M} \\
                        \vfg{0}_{M \times N} & \vfg{0}_{M \times M}
                    \end{pmatrix},
                \end{align}
                where $M = L - N$ is the number of virtual basis states.
                We compute the one-body density matrix by
                \begin{python}
o = slice(0, n)
rho_qp = np.zeros_like(h)
rho_qp[o, o] = C[:, o].conj().T @ s @ C[:, o]
                \end{python}
                where \pyth{n} is the number of occupied particles and \pyth{o}
                is a slice with the occupied indices.


        \subsection{Self consistent field procedure}
            Now, in order for us to solve the Roothan-Hall equations, we need an
            expression for the Fock matrix.
            However, the Fock matrix depends on the coefficients found from
            solving the Roothan-Hall equations.
            In order to get around this pickle, we use \emph{self consistent
            field iterations} to gradually converge towards a solution to the
            Roothan-Hall equations.
            We denote matrices at a specific step $i$ by a superscript $(i)$,
            e.g., the Fock matrix at step $i$ is denoted $\fockmat^{(i)}$.
            If there are no superscripts that means the matrix is independent of
            the self consistent iterations.
            The self consistent field method for the Roothan-Hall equations is
            then given by
            \begin{align}
                \fockmat^{(i)}\vfg{C}^{(i + 1)}
                = \overlapmat \vfg{C}^{(i + 1)}\vfg{\epsilon}^{(i + 1)}.
                \label{eq:ghf-scf-roothan-hall}
            \end{align}
            Here $\fockmat^{(i)}$ is built from the coefficient matrices at the
            previous timestep, i.e., $\vfg{C}^{(i)}$.
            The generalized eigenvalue equation is solved in the same manner as
            described in \autoref{subsec:ghf} yielding the coefficient matrix
            and the orbital eigenenergies for the next timestep.

            To start the self consistent iterations we need an initial value for
            the Fock matrix.
            We choose $\fockmat^{(0)} = \vfg{\oneten}$, i.e., we set the initial
            Fock matrix to be the one-body Hamiltonian matrix.
            The self consistent procedure can now be explained by the following
            steps:
            \begin{enumerate}
                \item Construct the Fock matrix $\fockmat^{(i)}$ from
                    \autoref{eq:ghf-fock-matrix}, or from the initial state if
                    $i = 0$.
                \item Solve \autoref{eq:ghf-scf-roothan-hall} to find
                    $\vfg{C}^{(i + 1)}$ and $\vfg{\epsilon}^{(i + 1)}$.
                \item Build the density matrix $\vfg{D}^{(i + 1)}$ from the
                    occupied coefficient matrices as in
                    \autoref{eq:ghf-density-matrix}.
                \item Check for convergence.
            \end{enumerate}
            The convergence of the self consistent iterations are determined by
            the change in energy and the change in the density matrix between
            two consecutive steps.
            That is, for two given tolerances $\delta_E$ and $\delta_D$, we say
            that the iterations have converged when both
            \begin{gather}
                \Delta \energy
                = \energy^{(i + 1)} - \energy^{(i)} < \delta_E,
                \\
                \norm{\Delta \vfg{D}}_{F}
                = \norm{\vfg{D}^{(i + 1)} - \vfg{D}^{(i)}}_{F}
                < \delta_D.
            \end{gather}
            are satisfied.
            The matrix norm is given by the Frobenius norm.
            % TODO: Cite Charlotte Fischer on convergence trouble
            % https://www.sciencedirect.com/science/article/pii/0010465587900531?via%3Dihub
            % TODO: Explain the mixing procedure.


        \subsection{The restricted Hartree-Fock method}
            In the restricted Hartree-Fock method we make the assumption that
            each spin-direction is doubly occupied by an orbital.
            This can be a valid assumption if the Hamiltonian is
            spin-independent\footnote{%
                We write \emph{can} as there are situations where the
                Hamiltonian is spin-independent, but subject to conditions where
                the spin-symmetry of the restricted spin-orbitals break.
                % TODO: This needs to be explained properly.
                % TODO: Demonstrate this using the bond-breaking of H2.
                % TODO: Check if this applies for low frequency 2d-dots.
            }.
            To be even more specific, we will look at the \emph{closed-shell
            restricted Hartree-Fock} method, i.e., each spin-orbital \emph{must}
            be doubly occupied and each energy shell must be completely filled.
            This corresponds the spin-restricted spin-orbitals from
            \autoref{eq:restricted-spin-orbital}.
            For a basis of $L$ spin-orbitals we get $L/2$ orbitals, where $L$
            must be an even number.
            We label the states by
            \begin{align}
                \phi_{P}(x) = \varphi_p(\vf{r}) \sigma(m_s)
                \implies
                \ket{\phi_P} = \ket{\varphi_p\sigma},
            \end{align}
            where $P \in \brac{1, \dots, L}$ and $p \in \brac{1, \dots, L / 2}$.
            That is, we use capital letters to refer to composite indices and
            lowercase letters for the orbitals.
            We write the ground state Slater determinant as
            \begin{align}
                \ket{\slat} = \ket{\phi_1 \phi_2 \dots \phi_{N - 1} \phi_N}
                = \ket{
                    (\varphi_1 \alpha)
                    (\varphi_1 \beta)
                    \dots
                    (\varphi_{N / 2} \alpha)
                    (\varphi_{N / 2}\beta)
                },
            \end{align}
            where $N$ is an even number of particles.
            The requirement that the molecular orbitals should be orthonormal is
            kept in the restricted Hartree-Fock method.
            As a consequence both the spin basis functions and the orbitals are
            orthonormal,
            \begin{align}
                \braket{\phi_P}{\phi_Q}
                = \braket{\sigma}{\tau}
                \braket{\varphi_p}{\varphi_q}
                = \delta_{\sigma \tau}
                \delta_{pq}
                = \delta_{PQ}.
            \end{align}
            Inserting the restricted spin-orbitals into the canonical
            Hartree-Fock equation, we get
            \begin{align}
                \fock\ket{\phi_P} = \epsilon_P\ket{\phi_P}
                \implies
                \fock\ket{\varphi_p\sigma}
                = \epsilon_P\ket{\varphi_p\sigma}.
            \end{align}
            By projecting onto a molecular orbital we demonstrate how we can
            construct the Fock matrix elements when the Hamiltonian is
            spin-independent.
            This gives
            \begin{align}
                \mel{\phi_P}{\fock}{\phi_Q}
                = \mel{\phi_P}{\onehamil}{\phi_Q}
                + \mel{\phi_P\phi_J}{\twohamil}{\phi_Q\phi_J}_{AS}.
                \label{eq:mo-fock-elements}
            \end{align}
            For the one-body Hamiltonian part of the Fock matrix elements we get
            \begin{align}
                \mel{\phi_P}{\onehamil}{\phi_Q}
                &= \braket{\sigma}{\tau}\mel{\varphi_p}{\onehamil}{\varphi_q}
                = \delta_{\sigma\tau}\mel{\varphi_p}{\onehamil}{\varphi_q}.
            \end{align}
            For the two-body part, we split up the antisymmetric elements into
            its constituent parts and show the spin-dependence in each terms
            separately.
            We start with the Coulomb operator giving
            \begin{align}
                \mel{\phi_P\phi_J}{\twohamil}{\phi_Q\phi_J}
                &= \braket{\sigma}{\tau}\braket{\nu}{\nu}
                \mel{\varphi_p\varphi_j}{\twohamil}{\varphi_q\varphi_j}
                = 2 \delta_{\sigma\tau}
                \mel{\varphi_p}{\hat{J}}{\varphi_q},
            \end{align}
            where we've introduced the restricted Coulomb operator from
            \autoref{eq:coulomb-operator}, and summed over the spin-dependence
            $\ket{\nu}$ from the two occupied orbitals in the two-body elements.
            That is,
            \begin{align}
                \braket{\nu}{\nu} = \delta_{\nu\nu} = 2.
            \end{align}
            The second term in the antisymmetric two body elements yields the
            exchange operator to be
            \begin{align}
                \mel{\phi_P\phi_J}{\twohamil}{\phi_J\phi_Q}
                &= \braket{\sigma}{\nu}\braket{\nu}{\tau}
                \mel{\varphi_p\varphi_j}{\twohamil}{\varphi_j\varphi_q}
                = \delta_{\sigma\tau}
                \mel{\varphi_p}{\hat{K}}{\varphi_q},
            \end{align}
            where we've used the completness relation for the spin of the
            occupied molecular orbitals, viz.
            \begin{align}
                \dyad{\nu}
                = \1 \in \mathbb{R}^{2 \times 2}.
            \end{align}
            Collecting the terms, we get the Fock matrix elements
            \begin{align}
                \mel{\phi_P}{\fock}{\phi_Q}
                &=
                \delta_{\sigma\tau}
                \brak{
                    \mel{\varphi_p}{\onehamil}{\varphi_q}
                    +
                    2
                    \mel{\varphi_p}{\hat{J}}{\varphi_q}
                    -
                    \mel{\varphi_p}{\hat{K}}{\varphi_q}
                }
                \\
                &= \delta_{\sigma\tau}
                \mel{\varphi_p}{\fock}{\varphi_q},
            \end{align}
            where we see that the spin-dependence has been removed from the
            orbital integrals.
            We can therefore restrict ourselves to the orbital integrals for the
            Fock matrix elements.
            This means that we only need to look for coefficients for the
            molecular orbitals in terms of a known atomic orbital basis without
            spin.
            That is,
            \begin{align}
                \ket{\varphi_p} = C_{\alpha p} \ket{\chi_{\alpha}},
            \end{align}
            where $\brac{\chi_{\alpha}}_{\alpha = 1}^{K}$ is our
            spin-independent basis of known atomic orbitals.
            By projecting the atomic orbitals onto the canonical Hartree-Fock
            equations we will again be left with the Roothan-Hall equations as
            seen in \autoref{eq:roothan-hall-general}.

        \subsection{Constructing the restricted Fock matrix}
            The difference between the restricted and the general Hartree-Fock
            methods lies in our calculation of the Fock matrix elements in the
            atomic orbital basis.
            We now have that
            \begin{align}
                \fockten_{\alpha\beta}
                &\equiv \mel{\chi_{\alpha}}{\fock}{\chi_{\beta}}
                =
                \mel{\chi_{\alpha}}{\onehamil}{\chi_{\beta}}
                +
                2
                \mel{\chi_{\alpha}}{\hat{J}}{\chi_{\beta}}
                -
                \mel{\chi_{\alpha}}{\hat{K}}{\chi_{\beta}},
            \end{align}
            where the Coulomb and the exchange operator depends on the full
            spin-dependent molecular orbitals.
            Looking at these two operators separately we have
            \begin{gather}
                \mel{\chi_{\alpha}}{\hat{J}}{\chi_{\beta}}
                =
                C^{*}_{j\gamma} C_{j\delta}
                \mel{\chi_{\alpha}\chi_{\gamma}}{
                    \twohamil
                }{\chi_{\beta}\chi_{\delta}}
                =
                C^{*}_{j\gamma} C_{j\delta}
                \twotensym^{\alpha\gamma}_{\beta\delta},
                \\
                \mel{\chi_{\alpha}}{\hat{K}}{\chi_{\beta}}
                =
                C^{*}_{j\gamma} C_{j\delta}
                \mel{\chi_{\alpha}\chi_{\gamma}}{
                    \twohamil
                }{\chi_{\delta}\chi_{\beta}}
                =
                C^{*}_{j\gamma} C_{j\delta}
                \twotensym^{\alpha\gamma}_{\delta\beta},
            \end{gather}
            where we've introduced the tensor notation for the elements of the
            two-body operator to be
            \begin{align}
                \twotensym^{\alpha\beta}_{\gamma\delta}
                \equiv
                \mel{\chi_{\alpha}\chi_{\beta}}{
                    \twohamil
                }{\chi_{\gamma}\chi_{\delta}},
            \end{align}
            where the greek letters indicate that the elements are expressed in
            the atomic orbital basis.
            Note that these elements are not antisymmetric as opposed to
            $\twoten^{\alpha\beta}_{\gamma\delta}$.
            We also introduce the restricted density matrix
            \begin{align}
                D_{\beta \alpha}
                \equiv 2 C^{*}_{\alpha i} C_{\beta i},
            \end{align}
            where $i \in \brac{1, \dots, N / 2}$, and $N$ is the number of
            particles.
            In Python we compute the density matrix in the same way as done for
            the general Hartree-Fock method, but now we choose the slice over
            the occupied indices to be \pyth{o = slice(0, n // 2)}, and multiply
            the density matrix by a factor $2$.
            The restricted Fock matrix elements in the atomic orbital basis can
            now be written
            \begin{align}
                \fockten_{\alpha\beta}
                &=
                \oneten_{\alpha\beta}
                + D_{\delta\gamma}
                \brak{
                    \twotensym^{\alpha\gamma}_{\beta\delta}
                    -
                    \half
                    \twotensym^{\alpha\gamma}_{\delta\beta}
                },
                \label{eq:atomic-fock-rhf}
            \end{align}
            In Python we compute the restricted Fock matrix by
            \begin{python}
fock_matrix = (
    h
    + np.tensordot(density_matrix, I, axes=((0, 1), (3, 1)))
    - 0.5 * np.tensordot(
        density_matrix, I, axes=((0, 1), (2, 1))
    )
)
            \end{python}
            where \pyth{density_matrix} is now the restricted density matrix and
            \pyth{I} are the two-body elements.
            Furthermore, the one-body Hamiltonian \pyth{h} is now
            spin-independent.
            By proceeding with the self-consistent field iterations solving the
            Roothan-Hall equations with \autoref{eq:atomic-fock-rhf} as the
            definition of the Fock matrix elements, we find the orbital
            coefficient matrix $\vfg{C} \in \mathbb{C}^{K \times L/2}$ which we
            use to transform to the restricted molecular orbitals.
            Once transformed, we are at liberty to introduce spin-redundancy to
            open up for non-restricted post Hartree-Fock methods, e.g., the
            coupled-cluster method.

            \subsubsection{Restricted Hartree-Fock energy}
                We can compute the ground-state restricted Hartree-Fock energy
                by inserting our expression for the restricted molecular
                orbitals into the energy functional in
                \autoref{eq:energy_func_hf}.
                This yields
                \begin{align}
                    \energy
                    &= \mel{\slat}{\hamil}{\slat}
                    = \mel{\phi_I}{\onehamil}{\phi_I}
                    + \half
                    \mel{\phi_I\phi_J}{
                        \twohamil
                    }{\phi_I\phi_J}_{AS}
                    \\
                    &=
                    D_{\beta\alpha}
                    \oneten_{\alpha\beta}
                    + \half\brak{
                        D_{\beta\alpha}
                        D_{\delta\gamma}
                        \twotensym^{\alpha\gamma}_{\beta\delta}
                        - \half
                        D_{\beta\alpha}
                        D_{\delta\gamma}
                        \twotensym^{\alpha\gamma}_{\delta\beta}
                    }
                    \\
                    &=
                    D_{\beta\alpha}
                    \brac{
                        \oneten_{\alpha\beta}
                        + \half D_{\delta\gamma}
                        \para{
                            \twotensym^{\alpha\gamma}_{\beta\delta}
                            - \half
                            \twotensym^{\alpha\gamma}_{\delta\beta}
                        }
                    }.
                    \label{eq:rhf-energy}
                \end{align}
                We compute the energy in Python by the snippet shown in
                \autoref{alg:rhf-energy}.
                \begin{algorithm}
                    \begin{python}
# term_{ab} <- D_{dc} I^{ac}_{bd}
term = np.tensordot(
    density_matrix, I, axes=((0, 1), (3, 1))
)
# term_{ab} <- term_{ab} -0.5 * D_{dc} I^{ac}_{db}
term -= 0.5 * np.tensordot(
    density_matrix, I, axes=((0, 1), (2, 1))
)

# term_{ab} <- h_{ab} + 0.5 term_{ab}
term = h + 0.5 * term

# energy = D_{ba} term_{ab}
energy = np.trace(np.dot(term, density_matrix))
                    \end{python}
                    \caption{In this snippet we demonstrate how to compute the
                    restricted Hartree-Fock energy from
                    \autoref{eq:rhf-energy}.}
                    \label{alg:rhf-energy}
                \end{algorithm}
                The one-body density matrix in the restricted Hartree-Fock
                method is computed in the same way as for the general
                Hartree-Fock method, but with the restricted coefficients and an
                extra factor from the double occupancy.

        \subsection{The unrestricted Hartree-Fock method}
            The unrestricted Hartree-Fock method allows the molecular orbitals
            to have independent orbitals for each spin-direction.
            Hence, we assume that the molecular orbitals can be described by
            spin-unrestricted spin-orbitals as seen in
            \autoref{eq:unrestricted-spin-orbital}.
            Introducing indices for the different molecular orbitals, we denote
            the spin-unrestricted molecular orbitals by
            \begin{align}
                \phi_P(x)
                &=
                \varphi^{\sigma}_{p}(\vf{r})
                \sigma(m_s)
                \implies
                \ket{\phi_P}
                = \ket{\varphi^{\sigma}_{p}\sigma},
            \end{align}
            where $P \in \brac{1, \dots, L}$, $\sigma \in \brac{\alpha, \beta}$,
            and $p \in \brac{1, \dots, L_{\sigma}}$.
            We have that $L = L_{\alpha} + L_{\beta}$, and we have refrained
            from labelling the lower case orbital indices as they always occur
            with a spin index.
            Note that there is no implicit sum over the label $\sigma$ in the
            orbital $\varphi^{\sigma}_{p}$ and the spin-function $\sigma(m_s)$.
            We can collect the orbitals in two sets
            $\brac{\varphi^{\sigma}_{p}}$, one for each spin-direction.
            The ground state Slater determinant can then be written
            \begin{align}
                \ket{\slat}
                &=
                \ket{\phi_1 \phi_2 \dots \phi_{N - 1} \phi_N}
                =
                \ket{
                    (\varphi^{\alpha}_{1}\alpha)
                    \dots
                    (\varphi^{\alpha}_{N_{\alpha}}\alpha)
                    (\varphi^{\beta}_{1}\beta)
                    \dots
                    (\varphi^{\beta}_{N_{\beta}}\beta)
                },
            \end{align}
            where $N_{\sigma}$ is the number of particles with spin
            $\sigma(m_s)$.
            Note the ordering of the spin-orbitals in the determinant.
            As the two sets of orbitals can be of different sizes, we can no
            longer be sure that there is an even number of spin states.
            We therefore stack the spin-orbitals after one another instead of
            interlacing them by odd and even positions.
            The orthonormality of the molecular orbitals is given by
            \begin{align}
                \braket{\phi_P}{\phi_Q}
                &= \delta_{PQ}
                = \braket{\sigma}{\tau}
                \braket{\varphi^{\sigma}_{p}}{\varphi^{\tau}_{q}},
            \end{align}
            where the overlap between two orbitals with differing spin is not
            necessarily zero.
            However, if the two spin-directions are the same, i.e., $\sigma =
            \tau$, we get
            \begin{align}
                \braket{\varphi^{\sigma}_{p}}{\varphi^{\sigma}_{q}}
                = \delta_{pq}.
            \end{align}
            Inserting the unrestricted spin-orbitals into the canonical
            Hartree-Fock equations yield
            \begin{align}
                \fock\ket{\phi_P}
                = \epsilon_P\ket{\phi_P}
                \implies
                \fock\ket{\varphi^{\sigma}_{p}\sigma}
                = \epsilon^{\sigma}_{p}\ket{\varphi^{\sigma}_{p} \sigma},
            \end{align}
            which demonstrates how each spin-component yields a different
            equation as the Fock eigenenergies $\epsilon^{\alpha}_{p}$ is in
            general different from $\epsilon^{\beta}_{p}$.
            By projecting onto another molecular orbital as in
            \autoref{eq:mo-fock-elements} we demonstrate how the spin yields two
            separate Fock matrices, one for each spin-direction.\footnote{%
                Note that this assumes a spin-independent Hamiltonian.
            }
            The one-body elements in the molecular orbital basis is given by
            \begin{align}
                \mel{\phi_P}{\onehamil}{\phi_Q}
                = \delta_{\sigma\tau}
                \mel{\varphi^{\sigma}_{p}}{
                    \onehamil
                }{\varphi^{\tau}_{q}},
            \end{align}
            while the Coulomb operator from the two-body elements is given by
            \begin{align}
                \mel{\phi_P\phi_J}{
                    \twohamil
                }{\phi_Q\phi_J}
                &=
                \delta_{\sigma\tau}
                \sum_{\rho \in \brac{\alpha, \beta}}
                \mel{\varphi^{\sigma}_{p}}{
                    \hat{J}^{\rho}
                }{\varphi^{\sigma}_{q}}.
            \end{align}
            We note that this term provides a coupling between the orbitals in
            both spin-directions as we get a sum over the two spin-directions.
            This is not the case for the exchange operator from the
            antisymmetric two-body elements.
            We have
            \begin{align}
                \mel{\phi_P\phi_J}{
                    \twohamil
                }{\phi_J\phi_Q}
                =
                \delta_{\sigma\tau}
                \mel{\varphi^{\sigma}_{p}}{
                    \hat{K}^{\sigma}
                }{\varphi^{\tau}_{q}}.
            \end{align}
            Collecting all the terms in order to find the Fock matrix, we get
            \begin{align}
                \mel{\phi_P}{\fock}{\phi_Q}
                &=
                \delta_{\sigma\tau}
                \brak{
                    \mel{\varphi^{\sigma}_{p}}{
                        \onehamil
                    }{\varphi^{\tau}_{q}}
                    +
                    \sum_{\rho \in \brac{\alpha, \beta}}
                    \mel{\varphi^{\sigma}_{p}}{
                        \hat{J}^{\rho}
                    }{\varphi^{\tau}_{q}}
                    -
                    \mel{\varphi^{\sigma}_{p}}{
                        \hat{K}^{\sigma}
                    }{\varphi^{\tau}_{q}}
                }.
            \end{align}
            This demonstrates how the spin yields two different Fock matrices
            from the canonical Hartree-Fock equations.
            That is,
            \begin{align}
                \mel{\varphi^{\sigma}_{p}}{
                    \fock^{\sigma}
                }{\varphi^{\sigma}_{q}}
                &=
                \mel{\varphi^{\sigma}_{p}}{
                    \onehamil
                }{\varphi^{\sigma}_{q}}
                +
                \sum_{\rho \in \brac{\alpha, \beta}}
                \mel{\varphi^{\sigma}_{p}}{
                    \hat{J}^{\rho}
                }{\varphi^{\sigma}_{q}}
                -
                \mel{\varphi^{\sigma}_{p}}{
                    \hat{K}^{\sigma}
                }{\varphi^{\sigma}_{q}},
            \end{align}
            where the spin label on the Fock matrix corresponds to the spin
            label of the exchange operator.
            We now look for a set of coefficients for the orbitals in each
            spin-direction in terms of our original atomic orbital basis,
            \begin{align}
                \ket{\varphi^{\sigma}_{p}}
                &= C^{\sigma}_{\kappa p} \ket{\chi_{\kappa}},
            \end{align}
            where we use the greek letters $\kappa$, $\lambda$, $\mu$, and $\nu$
            for the atomic orbitals to avoid confusion with the spin-functions
            $\alpha(m_s)$ and $\beta(m_s)$.
            Before we demonstrate how we can generate a set of equations in
            order to find the coefficient matrices $\vfg{C}^{\sigma} \in
            \mathbb{C}^{K \times L_{\sigma}}$, we motivate the spin-labelling of
            the Fock matrices in the atomic orbital basis.
            We define
            \begin{align}
                \fockten^{\sigma}_{\kappa\lambda}
                &\equiv
                \mel{\chi_{\kappa}}{\fock^{\sigma}}{\chi_{\lambda}}
                =
                \oneten_{\kappa\lambda}
                + \sum_{\rho \in \brac{\alpha, \beta}}
                \mel{\chi_{\kappa}}{
                    \hat{J}^{\rho}
                }{\chi_{\lambda}}
                - \mel{\chi_{\kappa}}{
                    \hat{K}^{\sigma}
                }{\chi_{\lambda}}
                \\
                &=
                \oneten_{\kappa\lambda}
                + \sum_{\rho \in \brac{\alpha, \beta}}
                (C^{\rho}_{\mu j})^{*}
                C^{\rho}_{\nu j}
                \twotensym^{\kappa\mu}_{\lambda\nu}
                -
                (C^{\sigma}_{\mu j})^{*}
                C^{\sigma}_{\nu j}
                \twotensym^{\kappa\mu}_{\nu\lambda}
                \\
                &=
                \oneten_{\kappa\lambda}
                + \sum_{\rho \in \brac{\alpha, \beta}}
                D^{\rho}_{\nu\mu}
                \twotensym^{\kappa\mu}_{\lambda\nu}
                -
                D^{\sigma}_{\nu\mu}
                \twotensym^{\kappa\mu}_{\nu\lambda},
            \end{align}
            where the density matrix along a certain spin-direction is defined
            similarly to the density matrices in the general Hartree-Fock
            method.
            Left-projecting the atomic orbital basis on the canonical
            Hartree-Fock equations acting on an orbital in the unrestricted
            regime yields
            \begin{gather}
                \mel{\chi_{\kappa}}{\fock^{\sigma}}{\varphi^{\sigma}_{p}}
                = \epsilon^{\sigma}_{p}
                \braket{\chi_{\kappa}}{\varphi^{\sigma}_{p}}
                \implies
                C^{\sigma}_{\lambda p}
                \mel{\chi_{\kappa}}{\fock^{\sigma}}{\chi_{\lambda}}
                = C^{\sigma}_{\lambda p} \epsilon^{\sigma}_{p}
                \braket{\chi_{\kappa}}{\chi_{\lambda}}
                \\
                \implies
                \fockten^{\sigma}_{\kappa \lambda}
                C^{\sigma}_{\lambda p}
                =
                \overlapten_{\kappa\lambda}
                C^{\sigma}_{\lambda p}
                \epsilon^{\sigma}_{p}
                \implies
                \vfg{F}^{\sigma}
                \vfg{C}^{\sigma}
                =
                \overlapmat
                \vfg{C}^{\sigma}
                \vfg{\epsilon}^{\sigma}.
                \label{eq:pople-nesbet}
            \end{gather}
            These coupled equations constitute the \emph{Pople-Nesbet
            equations}.
            They resemble the Roothan-Hall equations seen in the two previous
            methods in that they are generalized eigenvalue equations, but now
            we solve two sets of eigenvalue equations simultaneously.
            Note that the coupling between the two spin-directions occurs in the
            Fock matrix via the Coulomb operator.
            The self-consistent field iterations for the unrestricted
            Hartree-Fock method remains the same, but now we iterate equations
            for both spin-directions at the same time.

            \subsubsection{The unrestricted Hartree-Fock energy}
                Inserting our expression for the molecular orbitals into the
                energy functional we find the unrestricted Hartree-Fock energy.
                \begin{align}
                    \energy
                    &=
                    \mel{\slat}{\hamil}{\slat}
                    =
                    \mel{\phi_I}{\onehamil}{\phi_I}
                    +
                    \half
                    \mel{\phi_I\phi_J}{
                        \twohamil
                    }{\phi_I\phi_J}_{AS}
                    \\
                    &=
                    \sum_{\sigma \in \brac{\alpha, \beta}}\brac{
                        \mel{\varphi^{\sigma}_{i}}{
                            \onehamil
                        }{\varphi^{\sigma}_{i}}
                        + \half\brak{
                            \sum_{\tau \in \brac{\alpha, \beta}}
                            \mel{\varphi^{\sigma}_{i}}{
                                \hat{J}^{\tau}
                            }{\varphi^{\sigma}_{i}}
                            -
                            \mel{\varphi^{\sigma}_{i}}{
                                \hat{K}^{\sigma}
                            }{\varphi^{\sigma}_{i}}
                        }
                    }
                    \\
                    &=
                    \sum_{\sigma \in \brac{\alpha, \beta}}\brac{
                        D^{\sigma}_{\lambda\kappa}
                        \oneten_{\kappa\lambda}
                        + \half
                        \sum_{\tau \in \brac{\alpha, \beta}}
                        D^{\sigma}_{\mu\kappa}
                        D^{\tau}_{\nu\lambda}
                        \twotensym^{\kappa\lambda}_{\mu\nu}
                        - \half
                        D^{\sigma}_{\mu\kappa}
                        D^{\sigma}_{\nu\lambda}
                        \twotensym^{\kappa\lambda}_{\nu\mu}
                    }.
                \end{align}
                % TODO: Add one-body density matrix?

        \subsection{Time-evolution}
            Due to time limitations we have only implemented a time-dependent
            general Hartree-Fock method.
            From \autoref{eq:tdhf} we know that we can write the time-evolution
            of the molecular orbitals by
            \begin{align}
                i\hslash\dpd{}{t}\ket{\phi_i(t)}
                &= \fock(t)\ket{\phi_i(t)}.
            \end{align}
            We can now insert the linear combination for the molecular orbitals in
            terms of the known atomic orbital basis.
            The time-evolution of the molecular orbitals is kept in the
            coefficients leaving the atomic orbital basis static in time.
            This gives
            \begin{align}
                i\hslash\dpd{}{t}C_{\alpha i}(t)\ket{\chi_{\alpha}}
                &= \fock(t)C_{\alpha i}(t)\ket{\chi_{\alpha}}.
            \end{align}
            Left projecting with another state from the atomic orbitals we can rewrite
            the previous equation to
            \begin{gather}
                i\hslash\dpd{}{t}C_{\alpha i}(t)\braket{\chi_{\beta}}{\chi_{\alpha}}
                =
                C_{\alpha i}(t)\mel{\chi_{\beta}}{\fock(t)}{\chi_{\alpha}}
                \\
                \implies
                i\hslash \dot{C}_{\alpha i} \overlapten_{\beta\alpha}
                = C_{\alpha i}(t)\fockten_{\beta\alpha}(t)
                \implies
                i\hslash \vf{S}\dot{\vf{C}}
                = \fockmat(t)\vf{C}(t),
                \label{eq:tdhf-equations}
            \end{gather}
            where the time-dependent Fock matrix $\fockmat(t)$ contains the
            matrix elements
            \begin{align}
                \fockten_{\beta\alpha}(t)
                = \mel{\chi_{\beta}}{\fock(t)}{\chi_\alpha}.
            \end{align}
            We restrict ourselves to orthonormal atomic orbital basis sets as we
            start the time evolution after performing a ground state
            Hartree-Fock calculation and transforming to the orthonormal
            molecular orbital basis.
            In the case of atomic units with $\hslash = 1$ and orthonormal
            atomic orbitals we can write \autoref{eq:tdhf-equations} as
            \begin{align}
                \dot{\vf{C}} = -i\fockmat(t)\vf{C}(t).
                \label{eq:tdhf-orthogonal}
            \end{align}
            In case of non-orthogonal atomic orbitals, the orthonormalization
            procedure described in \autoref{subsec:basis-transformation} can be
            used to make the orbitals orthonormal prior to starting the
            time-evolution.
            % TODO: Add function computing the right-hand side
            % TODO: Discuss ravel of the matrix

        \subsection{Time-dependent energy}
            The time-dependent energy is computed in exactly same way as for the
            general Hartree-Fock method.
            We therefore re-use this functionality, but use the time-dependent
            coefficients for the density matrices.
            % TODO: Consider adding normalization

        \subsection{Time-dependent overlap}
            From \autoref{subsec:determinant-overlap} we an expression for the
            overlap of two Slater determinants.
            Due to the orthonormality of the atomic orbital basis, the
            time-dependent overlap is given by
            \begin{align}
                P(t)
                =
                \abs{\braket{\Phi(t)}{\Phi(0)}}^2
                &= \abs{\det(\vf{C}^{\dagger}(t)\vf{C}(0))}^{2},
            \end{align}
            where $\vf{C}(t)$ is the coefficient matrix of the time evolved states.
            % TODO: Consider adding normalization


    \section{Configuration interaction}
        As the main goal of this thesis has been to implement coupled-cluster
        solvers, the configuration interaction solver has not been worked at to
        such a large degree.
        We have therefore implemented a ``naïve'' configuration interaction
        solver where we create the full Slater determinant space and store it in
        memory.
        From this we also create the full Hamiltonian matrix $\hamilmat$.
        Our implementation thus quickly absorb too much memory and therefore
        limits the number of particles and basis functions that can be explored.
        To improve on the current scheme, an implementation of the \emph{direct
        CI} methods \cite{helgaker-molecular} along with only storing non-zero
        elements in $\hamilmat$ will yield a more powerfull method supporting
        more particles and basis functions.

        \subsection{Constructing the Slater determinant basis}
            We represent the Slater determinants as NumPy-arrays \cite{numpy} of
            bit strings using unsigned integers.
            The default choice is to use \pyth{np.uint64}, i.e., 64-bit unsigned
            integers with room for 64 single-particle states, but other options
            such as 32-bit and 16-bit unsignd integers are available.
            If we have a system with $L > 64$ we add more integers in the array
            thus allowing for an integer mutiple of $64$ single-particle states at
            a time.
            Let $b$ be the number of bits in an integer, then the number of
            integers needed for a single Slater determinant $N_i$ is given by
            \begin{align}
                N_i = \left\lfloor\frac{L}{b}\right\rfloor
                + q,
            \end{align}
            where $q$ is either one or zero by
            \begin{align}
                q = \begin{cases}
                    1 & L \mod b > 0, \\
                    0 & L \mod b = 0,
                \end{cases}
            \end{align}
            where $L \mod b$ is the remainder of the integer division.
            The number of Slater determinants $N_s$ is given by a recursive
            function $N_s(S)$ depending on the order $S$ of the truncation,
            \begin{align}
                N_s(S) = \begin{cases}
                    1, & S = 0, \\
                    N_s(S - 1) \frac{(N - [S - 1])(M - [S - 1])}{S^2}, & S > 0.
                \end{cases}
            \end{align}
            where $N$ is the number of particles, $M = L - N$ is the number of
            virtual states, and we've denoted the order $S$ as an integer where
            $1$ represents singles, $2$ doubles, and so forth.
            This formula counts the number of ways $N$ particles can be
            distributed among $M$ positions moving $S$ particles at a time.
            For a given truncation level, e.g., singles-and-doubles (CISD), the
            number of Slater determinants is then
            \begin{align}
                N_s = N_s(2) + N_s(1) + N_s(0),
            \end{align}
            where $N_s(0) = 1$ counts the reference state.
            In \autoref{tab:num-slater-determinants} we demonstrate how the
            number of Slater determinants increase as a function of truncation
            for a fixed number of particles.
            The storage cost of the Hamiltonian matrix $\hamilmat$ is uncanny
            going from CIS to CISDTQ as the storage increases by $7$ orders of
            magnitude.
            \begin{table}
                \centering
                \caption{In this table we demonstrate how the number of
                Slater determinants $N_s$ increase as a function of truncation
                level for $N = 4$ and $L = 80$.
                We've also included the number of bytes needed to store the
                Slater determinants using \pyth{np.uint64}, i.e., 64-bit
                unsigned integers to represent the determinants, and the size of
                the Hamiltonian matrix in bytes where we assume 128-bit complex
                numbers as elements.
                The storage cost of the Hamiltonian matrix for CIS was
                $\SI{0.001}{\giga\byte}$, which does not show up in the
                designated one decimal point.}
                \renewcommand{\arraystretch}{1.3}
                \begin{tabular}{@{}lrrr@{}}
                    \toprule
                    Truncation & $N_s$ & Determinant storage $[\si{\byte}]$
                    & Hamiltonian storage $[\si{\giga\byte}]$ \\
                    \midrule
                    CIS & $305$ & $2440$ & $0.0$ \\
                    CISD & $17405$ & $139240$ & $4.5$ \\
                    CISDT & $298605$ & $2388840$ & $1328.7$ \\
                    CISDTQ & $1581580$ & $12652640$ & $37273.7$ \\
                    \bottomrule
                \end{tabular}
                \label{tab:num-slater-determinants}
            \end{table}

            In our code we construct the Slater determinant basis by creating
            the reference determinant where we set the $N$ first bits in the
            array of unsigned integers and then create $N_s - 1$ copies of this
            state.
            The setting of a single-particle state in a bit string is done using
            the binary OR command.
            An example of the setting of single-particle states represented as
            bits is shown in \autoref{alg:set-state-68}.
            \begin{algorithm}
                \inputpython{implementation/solvers/determinants.py}{0}{13}
                \caption{An example of how set the single-particle state $68$ in
                a binary state array \pyth{state} using \pyth{np.uint64}
                integers to represent determinants.}
                \label{alg:set-state-68}
            \end{algorithm}
            Other options are to use the binary XOR operation, but whichever one
            is chosen some care must be shown as bugs can arise if the
            single-particle state is already set.
            In the case of the OR operation this does not change the state, but
            the XOR operation will remove the state.
            For this reason we use the XOR operation in order to unset a bit,
            i.e., remove a single-particle state.

            The higher excited determinants are created by exciting the
            reference determinant in a recursive fashion.
            The excitation operator for a single Slater determinant is shown in
            \autoref{alg:excite-state}.
            \begin{algorithm}
                \inputpython{implementation/solvers/determinants.py}{16}{23}
                \caption{Function used to represent a series of excitation
                operators $\hat{X}^{a}_{i}$, neglecting the sign.}
                \label{alg:excite-state}
            \end{algorithm}
            This function excites all single-particle states in the array
            \pyth{o_remove} to the single-particle states in \pyth{v_insert}.
            Note that the Slater determinants are interpreted as being in
            canonical ordering and we ignore the sign handling when creating the
            basis of determinants.
            The signs are thus handled when computing matrix elements.
            To populate the \pyth{o_remove}- and \pyth{v_insert}-arrays, we have
            a function which recursively adds an occupied index into
            \pyth{o_remove} and then proceeds to add all the virtual indices in
            order into \pyth{v_insert}, before calling the excitation function
            defined in \autoref{alg:excite-state}.
            This function is shown in
            \begin{algorithm}
                \inputpython{implementation/solvers/determinants.py}{26}{56}
                \caption{Function creating all excited determinants of a given
                order \pyth{order}.}
                \label{alg:create-excited-states}
            \end{algorithm}

            The entire implementation of the configuration interaction method is
            uniquely defined by the basis of Slater determinants.
            This means that after a truncation order has been chosen and the
            basis of Slater determinants has been constructed, everything that
            follows will be solved in the same manner independently of the
            truncation level.

        \subsection{Constructing the Hamiltonian matrix}
            The arguably most effective first order optimization that can be
            performed for the configuration interaction method is to implement
            the Slater-Condon rules when evaluating matrix elements of operator
            strings, as opposed to brute force evaluation of the action of the
            second quantized operators on a determinant.
            When constructing the Hamiltonian matrix $\hamilmat$ with one- and
            two-body operators, we wish to evaluate the matrix elements
            \begin{align}
                \hamilten_{IJ}
                = \mel{\Phi_{I}}{\hamil}{\Phi_J}
                =
                \oneten^{p}_{q}
                \mel{\Phi_{I}}{\ccr{p}\can{q}}{\Phi_J}
                +
                \frac{1}{4}
                \twoten^{pq}_{rs}
                \mel{\Phi_{I}}{
                    \ccr{p}
                    \ccr{q}
                    \can{r}
                    \can{s}
                }{\Phi_J},
            \end{align}
            using the Slater-Condon rules defined in
            \autoref{lemma:slater-condon-one-body} and
            \autoref{lemma:slater-condon-two-body}.
            Given two Slater determinants $\ket{\slat_I}$ and $\ket{\slat_J}$
            which we represent as two occupation number states $\ket{\vfg{n}}$
            and $\ket{\vfg{m}}$, respectively, we need ways to evaluate the
            following:
            \begin{itemize}
                \item The sign given by
                    \begin{align}
                        (\Gamma_{-})^{\vfg{n}}_{p}
                        = \prod_{i = 1}^{p - 1}(-1)^{n_i},
                    \end{align}
                    as defined in \autoref{def:creation_1}.
                \item The Kronecker-Delta $\delta_{p \in \vfg{n}}$ checking if
                    the single-particle state $p$ is an occupied state in
                    $\ket{\vfg{n}}$.
                \item The difference $\abs{\vfg{n} - \vfg{m}}$, between the two
                    determinants $\ket{\vfg{n}}$ and $\ket{\vfg{m}}$.
                \item The position of a set bit to a single-particle index $p$
                    in order to find the correct matrix elements in
                    $\oneten^{p}_{q}$ and $\twoten^{pq}_{rs}$.
            \end{itemize}
            For the sign calculation we use the product for the phase
            $(\Gamma_{-})^{\vfg{n}}_i$ defined in \autoref{def:creation_1} by
            counting the number of set bits $k$ at positions below $i$, and
            computing $(-1)^k$.
            An implementation of this sign calculation is shown in
            \autoref{alg:gamma-phase}.
            \begin{algorithm}
                \inputpython{implementation/solvers/determinants.py}{59}{72}
                \caption{Function computing the sign of the action of a creation
                or annihilation operator for index \pyth{p} on a determinant
                \pyth{state}.
                This is the binary implementation of the phase defined in
                \autoref{def:creation_1}.}
                \label{alg:gamma-phase}
            \end{algorithm}
            The implementation of the Kronecker-Delta is shown in
            \autoref{alg:kronecker-delta}.
            \begin{algorithm}
                \inputpython{implementation/solvers/determinants.py}{75}{81}
                \caption{Implementation of the Kronecker-Delta $\delta_{p \in
                \vfg{n}}$.}
                \label{alg:kronecker-delta}
            \end{algorithm}
            To compute the difference between the two determinants we start by
            using the XOR operation to find the specific bits that are set in
            either $\vfg{n}$ or $\vfg{m}$, but not both.
            Next, we count the number of set bits in this difference state.
            The counting of set bits in an integer is a topic which has been
            explored in some depth in the field of computer science and has led
            to some very efficient algorithms.
            We use the population count algorithm \cite{wiki:popcount} shown in
            \autoref{alg:popcount_64}.
            \begin{algorithm}
                \inputpython{implementation/solvers/determinants.py}{84}{97}
                \caption{Implementation of the popcount algorithm for 64-bit
                integers.}
                \label{alg:popcount_64}
            \end{algorithm}
            Now, counting the number of set bits in the difference-state from
            $\ket{\vfg{n}} \text{XOR} \ket{\vfg{m}}$ yields the difference
            $\abs{\vfg{n} - \vfg{m}}$.
            The function in \autoref{alg:state-diff} computes the difference
            between two determinants.
            \begin{algorithm}
                \inputpython{implementation/solvers/determinants.py}{100}{108}
                \caption{Function counting the difference in the number of
                single-particle states in two Slater determinants.}
                \label{alg:state-diff}
            \end{algorithm}
            To compute the index of a set bit in a bitstring we iterate over all
            bit positions in the bitstring and right-shift the bits before using
            the binary AND operation to check if the rightmost bit is set.
            Once we encounter a bit, the iteration counter contains the index of
            the bit.
            An implementation of this scheme is shown in
            \autoref{alg:get-index}.
            \begin{algorithm}
                \inputpython{implementation/solvers/determinants.py}{111}{125}
                \caption{Function computing the index of a set bit in Slater
                determinant.
                The parameter \pyth{index_num} decides if we should find the
                first (\pyth{0}), second (\pyth{1}), or higher, set bits.}
                \label{alg:get-index}
            \end{algorithm}
            % TODO: Add the implementation of the Slater-Condon rules?


        \subsection{Diagonalization}
            Having constructed the full Hamiltonian matrix $\hamilmat \in
            \mathbb{C}^{N_s \times N_s}$ the next step is to diagonalize the
            matrix in order to get the eigenenergies $\vfg{\energy} = \diag(E_1,
            \dots, E_{N_s})$ and the eigenvectors, i.e., the coefficients for
            the eigenstates, $\vfg{C} \in \mathbb{C}^{N_s \times N_s}$.
            As stated in \autoref{chap:ci}, we restrict our attention to
            orthonormal single-particle states and we therefore need to solve
            the eigenvalue equation
            \begin{align}
                \hamilmat\vfg{C} = \vfg{E}\vfg{C}.
            \end{align}
            The Hamiltonian matrix is Hermitian and we can therefore use the
            function \pyth{np.linalg.eigh} \cite{numpy}, which uses the
            LAPACK-routines \cite{laug} \pyth{_syevd} and \pyth{_heevd} for
            symmetrc and Hermitian matrices respectively, to solve the
            eigenvalue equation.
            This will yield the full spectrum of $\hamilmat$ and will often
            prove a limiting factor in terms of computational complexity as the
            number of FLOPS required to solve this equation scales as
            $\mathcal{O}(N_s^3)$.

            As an alternative to the full spectrum we can use a sparse
            eigenvalue solver.
            We use the function \pyth{scipy.sparse.linalg.eigsh} from SymPy
            \cite{sympy} which is a wrapper around the ARPACK routines SSEUPD
            and DSEUPD \cite{arpack} implementing the Implictly Restarted
            Lanczos Method with a theortical complexity of $\mathcal{O}(N_s^2)$.
            This lets us specify how many eigenpairs $k$ we wish to compute,
            which is then found iteratively.

            The eigensolvers given by NumPy \cite{numpy} and SciPy \cite{sympy}
            sorts the eigenvalues in an ascending order with the eigenvectors
            sorted in the same fashion, and with the eigenvectors unitary.
            This means that the ground state energy is found as the first
            element of the eigenvalues.

        \subsection{One-body density matrix}
            Having diagonalized the Hamiltonian matrix we can compute the one-body
            density matrix of the system.
            For a given eigenstate $\ket{\Psi_I}$ we compute the one-body
            density matrix by
            \begin{align}
                {\rho_I}^{q}_{p}
                &= \bra{\Psi_I}\ccr{p}\can{q}\ket{\Psi_I}
                = C_{JI}^{*}C_{KI}\bra{\slat_J}\ccr{p}\can{q}\ket{\slat_K}.
                \label{eq:ci-one-body-density}
            \end{align}
            As matrix elements of the one-body density matrix is given by a pair
            of creation and annihilation operators we can use the Slater-Condon
            rules for one-body operators to evaluate the overlap.
            This results in virtually the same implementation as for the
            one-body Hamiltonian, but with a new one-body operator given by the
            coefficient vector $\vfg{c}_I$ for a specific eigenstate
            $\ket{\Psi_I}$.
            Do note that $\vfg{c}_I \in \mathbb{C}^{N_s}$ and that the indices
            into this vector is given by the same indices as for the Slater
            determinants, unlike the single-particle indices used for the
            one-body density matrix and the one-body Hamiltonian.

        \subsection{Time-evolution}
            Having solved the ground state problem, we move on to the dynamics
            of the configuration interaction method.
            Choosing an initial state with a given coefficient vector
            $\vfg{c}(0) \in \mathbb{C}^{N_s}$, either from the ground state
            problem or from some other method, we prooceed to solve the
            differential equation demonstrated in \autoref{eq:tdci}.
            In atomic units this corresponds to solving
            \begin{align}
                \dot{\vfg{c}}(t) = -i\hamilmat(t)\vfg{c}(t).
            \end{align}
            Having already set up the framework for the numerical integrators as
            described in \autoref{sec:numerical-integration}, our task is to
            construct the time-dependent Hamiltonian matrix.
            In general we can construct the time-dependent matrix elements from
            \begin{align}
                \hamilten_{IJ}(t)
                &=
                \oneten^{p}_{q}(t)
                \bra{\slat_I}\ccr{p}\can{q}\ket{\slat_J}
                + \frac{1}{4}\twoten^{pq}_{rs}(t)
                \bra{\slat_I}\ccr{p}\ccr{q}\can{s}\can{r}\ket{\slat_J}.
            \end{align}
            and re-use the Slater-Condon rules to evaluate the one- and two-body
            operators.
            Our implementation does programmatically support a time-dependent
            two-body operator, but this is not something that we will use.
            Therefore, by only including time-dependent one-body operators, an
            optimization is to store two copies of the full Hamiltonian
            matrix,\footnote{%
                This might seem a little odd as we've already argued at length
                of how the Hamiltonian matrix is the bottleneck of the
                implementation, but remember that our focus is on the dynamics
                of quantum-mechanical systems and we are therefore quite limited
                in the size of the systems we can explore.
                This means that we will seldom look at very large systems and we
                can often store the full Hamiltonian matrix, and copies, in
                memory.
            }
            and only re-compute the time-dependent one-body contributions.
            We define the two sets of matrix elements for the Hamiltonian matrix
            by
            \begin{gather}
                (\hamil_1)_{IJ}(t)
                \equiv
                \mel{\slat_I}{\onehamil(t)}{\slat_J}, \\
                (\hamil_2)_{IJ}(t)
                \equiv
                \mel{\slat_I}{\twohamil(t)}{\slat_J}.
            \end{gather}
            Setting $\twohamil(t) = \twohamil$ we now compute the Hamiltonian
            matrix from
            \begin{align}
                \hamilmat(t)
                = \hamilmat_1(t) + \hamilmat_2,
            \end{align}
            where we only construct a new $\hamilmat_1(t)$ -- using the
            Slater-Condon rules for the one-body operator -- at every timestep.

        \subsection{Time-dependent energy}
            For a time-evolved state $\ket{\Psi(t)}$ with a time-evolved
            Hamiltonian $\hamil(t)$, we can compute the energy of the state at a
            certain time $t$ by
            \begin{align}
                E(t) = \frac{
                    \mel{\Psi(t)}{\hamil(t)}{\Psi(t)}
                }{
                    \braket{\Psi(t)}
                },
            \end{align}
            where we've included an explicit normalization due to potential
            drift in the coefficients from the time-evolution using numerical
            integrators.
            Expanding the time-evolved state in the static basis of Slater
            determinants with time-dependent coefficients, $\vfg{c}(t)$, we find
            the time-dependent energy to be
            \begin{align}
                E(t)
                &=
                \frac{
                    c^{*}_I(t)\mel{\slat_I}{\hamil(t)}{\slat_J}c_J(t)
                }{
                    c^{*}_I(t)c_I(t)
                }
                = \frac{
                    \vfg{c}^{\dagger}(t)\hamilmat(t)\vfg{c}(t)
                }{
                    \vfg{c}^{\dagger}(t)\vfg{c}(t)
                }.
            \end{align}


        \subsection{Time-dependent overlap}
            We compute the time-dependent overlap by
            \begin{align}
                P(t)
                =
                \frac{
                    \abs{\braket{\Psi(t)}{\Psi(0)}}^2
                }{
                    \braket{\Psi(t)}\braket{\Psi(0)}
                }
                = \frac{
                    \abs{\vfg{c}^{\dagger}(t)\vfg{c}(0)}^2
                }{
                    \abs{\vfg{c}(t)}^2
                    \abs{\vfg{c}(0)}^2
                },
            \end{align}
            where we again include an explicit normalization term in case of
            drift in the normalization due to the integrator.
            We also compute the overlap from the initial time $t = 0$.

    \section{Coupled cluster}
        In this thesis we have implemented a set of coupled-cluster solvers,
        they are:
        \begin{itemize}
            \item The coupled-cluster doubles (CCD) and the coupled-cluster
                singles-and-doubles (CCSD) methods with static orbitals.
                This includes both time-independent and time-dependent solvers.
            \item The non-orthogonal coupled-cluster doubles (NOCCD) ground
                state solver.
                Note that we often call this solver for the orbital-adaptive
                coupled-cluster doubles method (OACCD).
                This solver was written by \citeauthor{rolf-nocc}
                \cite{rolf-nocc} and given to use as part of an ongoing article
                on the stability of time-dependent coupled-cluster methods.
                We still describe the implementation in some detail as we had to
                integrate the solution into our library.
                % TODO: Cite ongoing article
            \item The orbital-adaptive time-dependent coupled-cluster doubles
                (OATDCCD) method.
                This method uses the OACCD method as an initial ground state
                solver.
        \end{itemize}
        Our coupled-cluster library tries in as large degree as possible to
        re-use routines for the different solvers as this makes optimization
        more efficient, that is, we only need to optizime a specific function
        once instead of once per solver.

        \subsection{Ground state solvers with static orbitals}
            From \autoref{chap:cc} we know that the projected amplitude
            equations from \autoref{eq:cc_amp_sim} should be satisfied once we
            have found the optimal $\clustamp_{\mu}$-amplitudes.
            However, in order to find the optimal amplitudes we employ an
            iterative \emph{quasi-Newton} method which avoids the need for
            computing the Jacobian matrix and solving a linear equation as in
            Newton's method \cite{helgaker-molecular}.
            We define the left-hand side of \autoref{eq:cc_amp_sim} with the
            normal-ordered Hamiltonian to be
            \begin{align}
                \Omega_{\mu}(\vfg{\clustamp}^{(i)})
                = \mel*{\slat_{\mu}}{
                    \exponential(-\clust^{(i)})
                    \hamil_N
                    \exponential(\clust^{(i)})
                }{\slat},
            \end{align}
            where $\vfg{\clustamp}^{(i)}$ is the collection of cluster
            amplitudes at iteration $i$ and $\mu$ denotes an excitation level.
            Note that we treat $\Omega_{\mu}$ as a tensor of rank $\mu$ in
            order to collect all elements from a cluster of rank $\mu$.
            % TODO: Link to amplitude equations

            In the quasi-Newton method we now solve \cite{bartlett-purvis,
            helgaker-molecular}
            \begin{align}
                \Delta \clustamp^{(i)}_{\mu}
                = \frac{\Omega_{\mu}(\vfg{\clustamp}^{(i)})}{
                    D_{\mu}
                },
                \label{eq:delta-tau}
            \end{align}
            in order to find the change in the amplitudes between two
            iterations.
            In the former equation $\mu$ serves as a label and should not be
            summed.
            The division is also interpreted as an element-wise division.
            Now, $D_{\mu}$ is a tensor of rank $\mu$ and serves as an
            approximation to the Jacobian matrix in case of a full fledged
            Newton's method \cite{helgaker-molecular}.
            For the singles and doubles amplitudes we have the tensors
            \begin{gather}
                D^{a}_{i} \equiv \epsilon_i - \epsilon_a, \\
                D^{ab}_{ij} \equiv \epsilon_i + \epsilon_j
                - \epsilon_a - \epsilon_b,
            \end{gather}
            where $\epsilon = \diag(\epsilon_1, \dots, \epsilon_L)$ are the
            diagonal elements of the normal-ordered Fock matrix.
            In order for \autoref{eq:delta-tau} to be well-defined we require
            that none of the elements in $D_{\mu}$ are zero.
            This is ensured as long as we have a well-defined single-reference
            problem as
            \begin{align}
                \epsilon_i \neq \epsilon_a,
            \end{align}
            for all $i \in \brac{1, \dots, N}$ and $a \in \brac{N + 1, \dots,
            L}$ when the single-reference assumption holds.
            However, do note that the lack of infinite precision on a computer
            means that we can get instabillities if we approach a system that is
            almost degenerate across the Fermi vacuum, that is, if we are almost
            in a multireference situation.
            % TODO: This sounds kinda sketchy!
            We are now able to compute the next iteration of the cluster
            amplitudes by
            \begin{align}
                \vfg{\clustamp}^{(i + 1)}
                = \vfg{\clustamp}^{(i)}
                + \Delta \vfg{\clustamp}^{(i)},
            \end{align}
            where we collect all the cluster amplitudes together when computing
            the improved estimate.

        \subsection{Non-orthogonal ground state solver}

        \subsection{Time-evolution with static orbitals}
        \subsection{Orbital-adaptive time-evolution}
