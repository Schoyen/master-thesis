\chapter{Quantum systems}
    In this chapter we'll discuss the different quantum systems which will be
    explored in this thesis.
    We'll discuss how we represent a general quantum system via the class
    \pyth{QuantumSystem} and the methods that this class incorporates.
    Before delving into the mathematics of quantum dots, and atoms and
    molecules, we will discuss what we want from our basis sets.
    \begin{enumerate}
        \item For all types of calculations we need access to the one- and
            two-body matrix elements of the Hamiltonian, and potentially the
            nuclear repulsion energy.
            That is, we need to find values for $\oneten^{p}_{q}$ and
            $\twoten^{pq}_{rs}$ as defined in \autoref{eq:h_pq} and
            \autoref{eq:u_pqrs} respectively.
            In case of a non-orthonormal basis set we also need the overlap
            matrix elements $\overlapten^{p}_{q}$ between the single-particle
            states.
        \item For time evolution, using a dipole laser we need the dipole matrix
            elements $\vfg{d}^{p}_{q}$ given by
            \begin{align}
                \vfg{d}^{p}_{q}
                = \mel*{\psi_p}{\hat{\vfg{d}}}{\psi_q},
            \end{align}
            as defined in \autoref{eq:dipole-moment}.
        \item For visualization of the particle density we need the
            single-particle states themselves, or at least the ability to
            evaluate the single-particle states on some grid.
    \end{enumerate}
    If our only interest is the ground state energy, we can get far with point 1
    listed above.
    However, for us to include interactions with a laser field we also need the
    dipole matrix elements as we are working in the dipole approximation.
    The single-particle states are necessary for visualization of the system on
    a grid either via the particle density or by themselves.
    We will visualize some of our systems to get a qualitative description of
    what we are looking at, but often we are more interested in quanitifying our
    results and the single-particle states are not necessarily needed.
    That is, they are of course needed when computing the integrals for the
    matrix elements, but an explicit evaluation of the single-particle states on
    a grid is not always necessary.
    The Python class \pyth{QuantumSystem} therefore builds the basis sets and
    serves as a container with the necessary matrix elements listed above, and
    methods for manipulating these elements.

    Often the limitation of basis sets comes from the calculation of the
    two-body matrix elements as these integrals will in many cases be the
    computational bottleneck.
    This is the reason why we often seek systems with analytical solutions to
    the most intensive integrals -- or easier integral evaluation -- and then do
    a basis transformation using the variational method, and eventually
    Hartree-Fock to build more complicated systems.
    As part of this thesis we have implemented several systems, they are:
    \begin{enumerate}
        \item The one-dimensional quantum dot on a grid supporting arbitrary
            one-dimensional potentials.
        \item The two-dimensional quantum dot in a harmonic oscillator, in a
            sharp double well, in a smooth double well, and subject to a
            magnetic field.
    \end{enumerate}
    In this thesis we will look briefly at the one-dimensional quantum dot.
    The two-dimensional quantum dots are discussed in the thesis by
    \citeauthor{greg-winther} \cite{greg-winther}.
    The main focus in this thesis are atoms and molecules.
    The subject of atomic and molecular basis sets is a vast topic in quantum
    chemistry \cite{helgaker-molecular}.
    To avoid reinventing the wheel we have implemented an interface towards the
    existing libraries PySCF \cite{pyscf} and Psi4 \cite{psi4} in order to get
    access to good and efficient basis sets for atoms and molecules.
    Furthermore, we will explore \emph{bound systems} which we take to mean that
    the underlying basis set will be trapped in a potential well and that the
    states will be held fixed in time.
    All time evolution occurs in the coefficients and amplitudes of the solver
    methods.
    This means that we will have a hard time modelling ionization as this
    requires the inclusion of continuum states to allow particles to move out of
    the trapping potential.
    An alternative is the usage of a time-dependent grid solver for the basis
    set \cite{miyagi_and_madsen}, but this has not been implemented in this
    thesis.


    \input{implementation/quantum-systems/quantum-dots.tex}

    \section{Atomic and molecular systems}
        \label{sec:atoms-and-molecules}
        Having discussed systems of quantum dots, or so-called ``artificial
        atoms'', we will now focus on actual atomic and molecular systems.
        As stated at the start of this chapter we make use of existing
        libraries to construct atomic and molecular basis sets.
        We will therefore touch briefly on the topic of atomic and molecular
        basis sets as much of the work therein will be treated as a black box.
        The molecular electronic one-body Hamiltonian in the Born-Oppenheimer
        approximation is given by \cite{basis-sets, hochstuhl2014time}
        \begin{align}
            \onehamil_i
            = -\half \nabla^2_i
            - \frac{Z_A}{\abs{\vfg{R}_A - \vfg{r}_i}},
        \end{align}
        where atomic units are assumed.
        Note that we sum over all nuclei $A$.
        Here we've left out the internuclear repulsion and the Coulomb
        interaction.
        Furthermore, in the Born-Oppenheimer approximation we treat the nuclei
        as being frozen and therefore ignore the kinetic energy contribution of
        the nuclear core.

        Now, perhaps not surprisingly the exact solution of the full molecular
        Hamiltonian\footnote{%
            Even in the Born-Oppenheimer approximation.
        } is a far fetched goal for all but the smallest systems to say the
        least.
        We can solve the molecular Hamiltonian in an approximate basis set.
        We can then diagonalize the one-body Hamiltonian and express the
        matrix elements in this new basis.
        As a consequence a lot of effort in the quantum chemistry field has been
        put into the construction of efficient and good basis sets.
        We will in this thesis use the following basis sets:
        \begin{itemize}
            \item The minimal Slater-type orbital (STO-$k$G) basis sets
                \cite{sto-3g}.
                Here $k$ denotes the number of Gaussian primitive functions used
                in a single basis function.
            \item The split-valence ($X$-$YZ$g) basis sets \cite{x-yzg}.
                Here $X$ denotes the number of primitive Gaussian functions for
                the core basis functions.
                The $Y$ and $Z$ tells us that there are two sets of basis
                functions with $Y$ and $Z$ basis functions for the valence
                orbitals respectively.
            \item The correlation-consistent polarized valence (cc-pV$X$Z) basis
                sets \cite{cc-pVXZ}.
                These basis sets are better tuned for post Hartree-Fock methods.
                The $X$ parameter decides the number of functions for the
                valence electrons, e.g., $D$ for double-zeta, $T$ for
                triple-zeta, etc.
            \item The augmented correlation-consistent (aug-cc-pV$X$Z) basis
                sets \cite{aug-cc-pVXZ}.
                The cc-pV$X$Z basis sets are designed for ground state
                calculations, but are inferior when it comes to describing
                excited states.
                The aug-cc-pV$X$Z basis functions alleviates some of this by
                incuding diffuse functions for the outer valence electrons
                \cite{helgaker-molecular}.
                The parameter $X$ is the same as in the case of the cc-pV$X$Z
                basis set.
        \end{itemize}
        To reuse the basis sets from PySCF \cite{pyscf} and Psi4 \cite{psi4}
        we've created a class \pyth{CustomSystem} which lets us build a
        \pyth{QuantumSystem}-class by manually setting the matrix elements.
        We can thus ask PySCF and Psi4 to use their well-optimized methods to
        generate basis sets and reuse these in our solvers.
        In this thesis we will only use basis sets from PySCF and we therefore
        only describe the interface towards this library.

        We've created three interface functions which sets up a
        \pyth{CustomSystem} of atomic orbitals, restricted molecular orbitals,
        and unrestricted molecular orbitals respectively.
        The two latter methods use the restricted and unrestricted Hartree-Fock
        solvers of PySCF.
        There are two main input parameters to these functions and that is
        \pyth{molecule} and \pyth{basis}.
        The former is a string describing the atom or molecule.
        In case of an atom it is enough to write the chemical symbol for the
        atom, e.g., \pyth{"he"} for Helium.
        For molecules the coordinates of the atoms contained in the system must
        be included.
        In the case of diatomic molecules we can then specify a bond distance
        along a specific axis, e.g., \pyth{f"h 0 0 0; h 0 0 1.2"} for the
        \ch{H2}-molecule with the bond distance $1.2$ specified in atomic units
        along the $z$-axis.
        The basis strings share the same format as discussed above, e.g., to
        specify the usage of aug-cc-pVDZ, we pass in the string
        \pyth{"aug-ccpvdz"} as the basis.


    \section{Particle density}
        \label{sec:particle-density}
        From \autoref{subsec:particle-density} we know how to compute the
        one-body particle density once we have found the one-body density matrix
        from a specific solver.
        For variational methods where the dual state of $\ket*{\phi_p}$ is the
        adjoint $\bra*{\phi_p}$ we can use the expression in
        \autoref{eq:particle-density}.
        However, as we are focusing much of our work on the bi-variational
        formulation of coupled-cluster we will implement the more general
        particle-density calculation
        \begin{align}
            \densityten(x)
            = \tilde{\phi}_{q}(x)
            \densityten^{q}_{p}
            \phi_p(x),
        \end{align}
        where $\tilde{\phi}_q(x)$ is the bi-variational dual state of
        $\phi_p(x)$.
        For the Hartree-Fock methods and configuration-interaction solvers we
        choose $\tilde{\phi}_q(x) = \phi^{*}_q(x)$ and we have recovered the
        original expression for the particle density as seen in
        \autoref{eq:particle-density}.
        In \autoref{alg:particle-density} we've included the code used to
        compute the particle density given a one-body density matrix denoted
        \pyth{rho_qp}, and the set of orbitals \pyth{bra_spf} and \pyth{ket_spf}
        as the bra- and ket-states respectively.
        We let the first index (the rows) of the orbital arrays denote the
        orbital index $p$, $q$, etc, whereas the remaining indices define the
        evaluation of the function on a $d$-dimensional grid $x \in
        \mathbb{C}^{d}$.
        \begin{algorithm}
            \begin{python}
def compute_particle_density(rho_qp, bra_spf, ket_spf):
    rho = np.zeros(ket_spf.shape[1:], dtype=ket_spf.dtype)
    spf_slice = slice(0, ket_spf.shape[0])

    for _i in np.ndindex(rho.shape):
        i = (spf_slice, *_i)
        rho[_i] += np.dot(bra_spf[i], np.dot(rho_qp, ket_spf[i]))

    return rho
            \end{python}
            \caption{In this listing we've added a function computing the
            particle density on an arbitrary grid that the orbitals are
            evaluated on.}
            \label{alg:particle-density}
        \end{algorithm}

    \section{Change of basis}
        \label{sec:change-of-basis}
        Much of what we do in this thesis is related to basis transformations.
        Either by diagonalization of the one-body Hamiltonian, an initial
        Hartree-Fock calculation, or in the orbital rotations in the
        non-orthogonal and orbital-adaptive coupled-cluster methods.
        A basis transformation can in general be represented by
        \begin{align}
            \ket*{\psi_p} = C_{\alpha p} \ket*{\phi_{\alpha}},
            \label{eq:spf-basis-change}
        \end{align}
        where we use greek indices to denote a basis of $K$ orbitals
        $\brac{\phi_{\alpha}}$ and latin letters for the basis of $L$
        transformed orbitals $\brac{\psi_p}$, and where $\vfg{C} \in
        \mathbb{C}^{K\times L}$ is a complex matrix with the coefficients
        necessary for the transformation.

        Having found the coefficient matrix $\vfg{C}$ we can change basis for
        all the existing matrix elements stored in the
        \pyth{QuantumSystem}-class.
        We will also here assume for the sake of generality that the dual states
        $\tilde{\psi}_p$ and $\tilde{\phi}_{\alpha}$ are not necessarily the
        adjoints of $\psi_p$ and $\phi_{\alpha}$.
        This means that
        \begin{align}
            \bra*{\tilde{\psi}_p}
            = \tilde{C}_{p \alpha}\bra*{\tilde{\phi}_{\alpha}}.
            \label{eq:spf-dual-basis-change}
        \end{align}
        Take extra note of the ordering of the indices in the coefficients in
        the dual basis transformation.
        In the case of adjoint states we have the familiar $\tilde{C}_{p \alpha}
        = C^{*}_{\alpha p}$.
        From the list of contents in \pyth{QuantumSystem} at the top of this
        chapter, we have three types of basis transformations that we need to
        support to fully change our system.
        We need to be able to change basis for one- and two-body matrix
        elements, and for the single-particle functions.

        We denote arbitrary one-body matrix elements of the one-body matrix
        $\vfg{\oneten}$ in the original orbital basis by
        \begin{align}
            \oneten_{\alpha \beta}
            \equiv
            \mel*{\tilde{\phi}_{\alpha}}{\onehamil}{\phi_{\beta}}.
        \end{align}
        Transforming to the new basis set we have
        \begin{gather}
            \tilde{\oneten}_{pq}
            = \mel*{\tilde{\psi}_p}{\onehamil}{\psi_q}
            =
            \tilde{C}_{p\alpha}
            \oneten_{\alpha \beta}
            C_{\beta q}
            \implies
            \tilde{\vfg{\oneten}}
            = \tilde{\vfg{C}}
            \vfg{\oneten}
            \vfg{C},
        \end{gather}
        where $\tilde{\vfg{\oneten}}$ is the transformed one-body elements.
        An implementation of the change of basis for the one-body elements is
        shown in \autoref{alg:transform-one-body-elements}.
        In the case of the dipole moments we store these as an array of one-body
        elements, one for every dimension, which means that we need to transform
        each axis using the algorithm in
        \autoref{alg:transform-one-body-elements}.
        \begin{algorithm}
            \begin{python}
def transform_one_body_elements(h, c, c_tilde=None):
    if c_tilde is None:
        c_tilde = c.conj().T

    return c_tilde @ h @ c
            \end{python}
            \caption{This function changes basis for the one-body matrix
            elements given a coefficient matrix \pyth{c} and an optional dual
            coefficient matrix \pyth{c_tilde}.}
            \label{alg:transform-one-body-elements}
        \end{algorithm}
        For the two-body elements we denote the elements by
        \begin{align}
            \twoten^{\alpha\beta}_{\gamma\delta}
            \equiv
            \mel*{\tilde{\phi}_{\alpha}\tilde{\phi}_{\beta}}{
                \twohamil
            }{\phi_{\gamma}\phi_{\delta}},
        \end{align}
        where we do not care if the elements are antisymmetric or not as it does
        not change the basis transformation.
        The transformation can now be done by
        \begin{align}
            \tilde{\twoten}^{pq}_{rs}
            = \mel*{\psi_p\psi_q}{
                \twohamil
            }{\psi_r\psi_s}
            = \tilde{C}_{p\alpha}
            \tilde{C}_{q\beta}
            \twoten^{\alpha\beta}_{\gamma\delta}
            C_{\gamma r}
            C_{\delta s}.
        \end{align}
        In \autoref{alg:transform-two-body-elements} we demonstrate the function
        which changes the basis for the two-body elements.
        We make use of temporary storage of a two-body matrix \pyth{_u} which
        lowers the cost of the basis transformation from $\mathcal{O}(L^8)$ to
        $\mathcal{O}(L^5)$.
        \begin{algorithm}
            \begin{python}
def transform_two_body_elements(u, c, c_tilde=None):
    if c_tilde is None:
        c_tilde = c.conj().T

    # abcd, ds -> abcs
    _u = np.tensordot(u, c, axes=(3, 0))
    # abcs, cr -> absr -> abrs
    _u = np.tensordot(_u, c, axes=(2, 0)).transpose(0, 1, 3, 2)
    # abrs, qb -> arsq -> aqrs
    _u = np.tensordot(_u, c_tilde, axes=(1, 1)).transpose(
        0, 3, 1, 2
    )
    # pa, aqrs -> pqrs
    _u = np.tensordot(c_tilde, _u, axes=(1, 0))

    return _u
            \end{python}
            \caption{This function changes the basis of the two-body elements
            given a coefficient matrix \pyth{c} and an optional dual matrix
            \pyth{c_tilde}.}
            \label{alg:transform-two-body-elements}
        \end{algorithm}
        For the single-particle functions the basis transformation is performed
        by \autoref{eq:spf-basis-change} and \autoref{eq:spf-dual-basis-change}
        where the states are projected on a grid.
        We represent all the single-particle states as a $d + 1$-dimensional
        array, where the first axis denotes which single-particle state we are
        looking at, and the $d$-remaining axes denotes the grid.
        In \autoref{alg:transform-spfs} we show the member function of
        \pyth{QuantumSystem} for changing the single-particle state basis.
        \begin{algorithm}
            \begin{python}
class QuantumSystem:
    # Code removed for clarity

    def change_basis_spf(self, c, c_tilde=None):
        if c_tilde is not None:
            # In case of bi-orthogonal basis sets, we create an
            # extra set of single-particle functions for
            # the bra-side
            self._bra_spf = self.np.tensordot(
                c_tilde,
                self._spf.conj()
                if self._bra_spf is None else self._bra_spf,
                axes=((1), (0)),
            )

        self._spf = self.np.tensordot(
            c, self._spf, axes=((0), (0))
        )
            \end{python}
            \caption{Here we list the member function in \pyth{QuantumSystem}
            that transforms the single-particle states given a coefficient
            matrix \pyth{c} and an optional dual matrix \pyth{c_tilde}.
            The single-particle states are denoted \pyth{self._spf} and
            \pyth{self._bra_spf} in case of a dual state that is not the adjoint
            state.}
            \label{alg:transform-spfs}
        \end{algorithm}


    \section{Spin-doubling}
        The basis sets we are exploring are always formulated as spatial
        orbitals without any spin component.
        Furthermore, we look at spin-independent Hamiltonians for the most
        part\footnote{%
            We explore a spin-dependent laser field to some extent as will be
            demonstrated in the results.
        } and a restricted solution can be used where we incorporate the spin by
        reusing the doubly occupied orbitals.
        We will use this to some extent for the restricted Hartree-Fock solver
        which will be discussed in \autoref{subsec:rhf}.
        However, most of the methods we've implemented make no assumption on the
        spin-orbitals other than there being two spin-components, and therefore
        allow general spin-orbitals as discussed in
        \autoref{subsec:restrictions-on-spin-orbitals}.
        This means that after we've created our basis sets, we include spin by
        making the system doubly degenerate in each orbital.

        The ordering of the spin-orbitals are important as some solvers
        exploit the spin-degeneracy and therefore need to know how the
        spin-orbitals are ordered.
        We've chosen a solution which is far from optimal, but which is
        reasonable as long as we have an even number of particles with the same
        amount of particles in each spin-direction.
        We use the convention that orbitals are ordered in an increasing order
        based on their single-particle eigenenergy.\footnote{%
            This is the ordering that is returned by NumPy when diagonalizing
            the one-body Hamiltonian.
        }
        We then double the length of each orbital axis in the single-particle
        functions,\footnote{%
            Except for the grid axes.
        } the one-body- and two-body Hamiltonians, and all other matrix
        elements.
        Next we repeat each orbital twice so that even indices correspond to a
        certain spin-direction and odd indices to the other direction.
        We are able to achieve this quite succintly using the Kronecker-product
        and slicing in NumPy.
        In \autoref{alg:spin-doubling-spf} we demonstrate a snippet which adds
        spin to a set of orbitals defined on an arbitrary grid.
        \begin{algorithm}
            \begin{python}
class QuantumSystem:
    # Code removed for clarity

    def change_to_spin_orbital_basis(self, anti_symmetrize=True):
        # Code removed for clarity

        if not self._spf is None:
            new_shape = [
                self._spf.shape[0] * 2, *self._spf.shape[1:]
            ]

            spf = self.np.zeros(
                tuple(new_shape), dtype=self._spf.dtype
            )
            spf[::2] += self._spf
            spf[1::2] += self._spf

            self._spf = spf
            assert self._spf.shape[0] == self.l
            \end{python}
            \caption{Spin-doubling of the single-particle functions.}
            \label{alg:spin-doubling-spf}
        \end{algorithm}
        For the one-body elements we use the function listed in
        \autoref{alg:spin-doubling-one-body}.
        The two-body elements requires us to do some more work as the Kronecker
        product gets applied to the two last indices of the array.
        We also want the product to be applied to pairwise indices that interact
        in the two-body integrals.
        This requires some transposing of the elements, and is shown in
        \autoref{alg:spin-doubling-two-body}.
        \begin{algorithm}
            \begin{python}
def add_spin_one_body(h):
    return np.kron(h, np.eye(2))
            \end{python}
            \caption{Function adding spin to one-body matrix elements, that is,
            matrices.}
            \label{alg:spin-doubling-one-body}
        \end{algorithm}
        \begin{algorithm}
            \begin{python}
def add_spin_two_body(_u):
    u = _u.transpose(1, 3, 0, 2)
    u = np.kron(u, np.eye(2))
    u = u.transpose(2, 3, 0, 1)
    u = np.kron(u, np.eye(2))
    u = u.transpose(0, 2, 1, 3)

    return u
            \end{python}
            \caption{Function adding spin to the two-body elements.}
            \label{alg:spin-doubling-two-body}
        \end{algorithm}

        A more general solution -- and which should be implemented in the future
        -- is to create spin-blocks with each spin-direction following each
        other as this allows for an unequal number of particles in each
        spin-direction.
        This is the solution that needs to be taken for the unrestricted
        Hartree-Fock method when changing basis.

    \section{Time evolution operators}
        The only time evolution operators used in this thesis are dipole lasers
        in the length gauge.
        We've implemented this by allowing \pyth{QuantumSystem} to have a
        pointer to a \pyth{TimeEvolutionOperator}-class, where \pyth{LaserField}
        is a subclass.
        The \pyth{LaserField}-class takes in the parameter \pyth{laser_pulse}
        and an optional \pyth{polarization_vector}.
        The former parameter is the electric field of the laser including the
        envelope function, whereas the latter defines which axis to polarize
        along.
        By default the polarization vector is set along the $x$-axis, that is,
        the first axis.
        Note that \pyth{QuantumSystem} so far does not have a charge which means
        that for negative charge either the pulse or the polarization vector
        needs to incorporate this sign.
        Both \pyth{laser_pulse} and \pyth{polarization_vector} can be constants
        or functions of a single parameter; time.
        We restrict our attention to a constant linear polarization, but we use
        time-dependent laser pulses.
        To specify a laser pulse, the user creates a function or a class with a
        \pyth{__call__}-method which takes in a single parameter as time.
        This function should return the electric field at the given time
        including the envelope function.

    \section{Measuring the dipole moment}
        In order to measure the dipole moment in time we use the one-body
        density matrix from the given solver to compute
        \begin{align}
            \expval*{\vfg{d}(t)}
            = \densityten^{q}_{p}(t)\vfg{d}^{p}_{q},
        \end{align}
        where the time-dependence is kept in the one-body density matrix.
        For the time-dependent Hartree-Fock method and the orbital-adaptive
        time-dependent coupled-cluster methods we have to make sure that we
        change basis at each time step before computing the trace of the
        one-body density matrix and the dipole moment.
        This yields a time-dependent dipole moment.
        Note also that we choose a specific axis of the dipole moment.

\clearemptydoublepage
