\chapter{Quantum mechanics}
    \epigraph{The underlying physical laws necessary for the mathematical
    theory of a large part of physics and the whole of chemistry are thus
    completely known, and the difficulty is only that the exact application of
    these laws leads to equations much too complicated to be soluble.}
    {--- P. A. M. Dirac}

    We start our journey by reviewing parts of quantum mechanics that we deem
    necessary in order to understand the thesis.

    \section{The postulates of quantum mechanics}
        In order to make sure that we have a common understanding of how to
        understand and interpret quantum mechanics we begin by introducing the
        postulates of quantum mechanics.
        The postulates were originally developed by Dirac
        \cite{dirac1981principles} and Neumann \cite{von2018mathematical},
        but have since been subject to interpretation.
        This has lead to many versions of the postulates, both in the number of
        postulates, and in the accuracy in their description.
        We will base our description of the postulates of quantum mechanics from
        the book \citetitle{salasnich2017quantum} by
        \citeauthor{salasnich2017quantum} \cite{salasnich2017quantum}.

    \section{Canonical quantization}
        \subsection{The Schrödinger equation}

    \section{Time-independent Schrödinger equation}
    \section{The variation principle}
        \subsection{The variation method}
    \section{The Hellmann-Feynman theorem}
        The Hellmann-Feynman theorem provides us with a method of calculating
        first-order change (also known as a first order property) in the energy
        due to a perturbation \cite{helgaker-molecular}.
        \begin{theorem}
            If $\ket{\psi}$ is a normalized eigenstate of the Hamiltonian
            $\hamil$, or $\ket{\psi}$ is variationally determined from the
            Hamiltonian $\hamil$, the Hellmann-Feynman theorem \cite{feynman}
            states that
            \begin{align}
                \left.\dod[]{E(\alpha)}{\alpha}\right\rvert_{\alpha = 0}
                =
                \left.
                \dpd[]{}{\alpha}
                \bra{\psi_{\alpha}}\hamil + \alpha\hat{V}\ket{\psi_{\alpha}}
                \right\rvert_{\alpha = 0}
                = \bra{\psi}\hat{V}\ket{\psi},
                \label{eq:hellmann-feynman}
            \end{align}
            where $\alpha$ is a perturbational parameter and $\hat{V}$ the
            perturbation operator.
            The wave function $\ket{\psi_{\alpha}}$ is given by
            \begin{align}
                \ket{\psi_{\alpha}} = N(\ket{\psi} + \alpha\ket{\delta\psi}),
            \end{align}
            where $N$ is a normalization factor.
            For approximate wave functions, they must be optimized with respect
            to the same variational parameter $\alpha$ as in the theorem.
        \end{theorem}
        \begin{proof}
            The underlying assumption is that
            \begin{align}
                \hamil\ket{\psi} = E\ket{\psi},
            \end{align}
            regardless if we have an exact or a variationally determined wave
            function $\ket{\psi}$.
            Furthermore, both perturbed and unperturbed wave functions are
            normalized, viz.
            \begin{align}
                \braket{\psi}{\psi} = \braket{\psi_{\alpha}}{\psi_{\alpha}} = 1
                \implies
                \dpd[]{}{\alpha} = \braket{\psi_{\alpha}}{\psi_{\alpha}} = 0.
            \end{align}
            See reference \cite{helgaker-molecular} for a proof where the
            normalization of the perturbed wave function is relaxed.
            We now prove \autoref{eq:hellmann-feynman} directly.
            \begin{align}
                \left.\dod[]{E(\alpha)}{\alpha}\right\rvert_{\alpha = 0}
                &=
                \left.
                \dpd[]{}{\alpha}
                \bra{\psi_{\alpha}}\hamil + \alpha\hat{V}\ket{\psi_{\alpha}}
                \right\rvert_{\alpha = 0}
                \\
                &=
                \bra{\delta\psi}\hamil\ket{\psi}
                + \bra{\psi}\hat{V}\ket{\psi}
                + \bra{\psi}\hamil\ket{\delta\psi}
                \\
                &=
                \energy \brak{
                    \braket{\delta\psi}{\psi}
                    + \braket{\psi}{\delta\psi}
                }
                + \bra{\psi}\hat{V}\ket{\psi}
                \\
                &=
                \energy \dpd[]{}{\alpha}\braket{\psi}{\psi}
                + \bra{\psi}\hat{V}\ket{\psi}
                \\
                &=
                \bra{\psi}\hat{V}\ket{\psi},
            \end{align}
            which is what we wanted to show.
        \end{proof}
    \section{Time-dependent Schrödinger equation}
    \section{The time evolution operators}
        We will in the following subsection stay close to the derivation of
        \citeauthor{ullrich2011time} \cite{ullrich2011time}, section 3.1.2, and
        \citeauthor{joachain2012atoms} \cite{joachain2012atoms}, section 5.1.
        Any solution to the time-dependent Schrödinger equation is given by
        \begin{align}
            \ket{\Psi(t)} = \hat{U}(t, t_0)\ket{\Psi(t_0)},
        \end{align}
        where $\hat{U}(t, t_0)$ is the time evolution operator that acts on the
        initial state $\ket{\Psi(t_0)}$, and yields the state $\ket{\Psi(t)}$ at
        some later time $t$. The time evolution operators are unitary at common
        times, viz.
        \begin{align}
            \hat{U}^{\dagger}(t, t_0)\hat{U}(t, t_0) = \1.
        \end{align}
        This means that we can go ``backwards in time'' in the sense that going
        from $\ket{\Psi(t)} \to \ket{\Psi(t_0)}$ is done by
        \begin{align}
            \ket{\Psi(t_0)} = \hat{U}^{\dagger}(t, t_0)\ket{\Psi(t)}.
        \end{align}
        Furthermore, we can compose a time evolution operator from other time
        evolution operators as
        \begin{align}
            \hat{U}(t_2, t_0) = \hat{U}(t_2, t_1)\hat{U}(t_1, t_0),
        \end{align}
        where $t_2 \geq t_1 \geq t_0$. If the Hamiltonian is time-independent,
        i.e., $\hat{H}(t) = \hat{H}$, the time evolution operator takes on the
        form
        \begin{align}
            \hat{U}(t, t_0) = \exp\brac{
                \frac{-i \hat{H} (t - t_0)}{\hslash}
            }.
            \label{eq:ti-evolution}
        \end{align}
        However, if the Hamiltonian is time-dependent, the time evolution
        operator takes on a much more complicated shape.
        \begin{align}
            \hat{U}(t, t_0) =
            \mathcal{T}\exp\brac{
                -\frac{i}{\hslash} \int_{t_0}^{t} \dd\tau
                \hat{H}(\tau)
            },
            \label{eq:td-evolution}
        \end{align}
        where $\mathcal{T}$ is the time-ordering operator. As an extra
        complicating factor, the time-dependent Hamiltonian might not commute
        with itself at different times. Here \autoref{eq:ti-evolution} and
        \autoref{eq:td-evolution} serve as the theoretical foundation for how
        the time-evolution is practically done in a numerical scheme.


    \section{Density operator}
        When working with many-body quantum mechanics, computing expectation
        values can at times prove easier when done using density matrices. A
        general density matrix of a \emph{pure state} is on the form
        \begin{align}
            \densitymatrix = \ket{\psi}\bra{\psi},
        \end{align}
        that is, a pure state is a quantum state $\ket{\psi}$ containing the
        maximum amount of information about a given system. For a \emph{mixed
        state}, i.e., a linear combination of pure states $\ket{\psi_k}$ with a
        classical probability $p_k$ associated with the state, we get a density
        matrix on the form
        \begin{align}
            \densitymatrix = \sum_{k} p_k \ket{\psi_k}\bra{\psi_k}.
        \end{align}
        Any density operator must satisfy the following
        properties \cite{modern-qm}:
        \begin{enumerate}
            \item Hermiticity, that is
                \begin{align}
                    p_k = p_k^{*} \implies \densitymatrix = \densitymatrix^{\dagger}.
                \end{align}
                This translates to the probabilities being real, $p_k \in
                \mathbb{R}$.
            \item Positivity,
                \begin{align}
                    p_k \geq 0 \implies \bra{\chi}\densitymatrix\ket{\chi} \geq 0.
                \end{align}
                In other words, density matrices are \emph{positive
                semidefinite}.
            \item Normalization of the probabilities,
                \begin{align}
                    \sum_{k} p_k = 1 \implies \tr(\densitymatrix),
                \end{align}
                that is, the probabilities must sum up to one.
        \end{enumerate}
        Furthermore, by squaring the density matrix and taking the trace we can
        infer if the system we are perusing is in a mixed state or a pure state
        \cite{modern-qm}.
        \begin{align}
            \tr(\densitymatrix^2) = \sum_{k} p_k^2 \leq 1,
        \end{align}
        with equality if, and only if, the system is in a pure state, viz.
        \begin{align}
            \densitymatrix = \ket{\psi}\bra{\psi}
            \implies \densitymatrix^2 = \densitymatrix
            \implies \tr(\densitymatrix^2) = 1.
        \end{align}
        Using density matrices, we can compute the expectation value of any
        operator $\hat{O}$, by \cite{modern-qm}
        \begin{align}
            \expv{\hat{O}} = \tr(\hat{O}\densitymatrix).
        \end{align}
        % TODO: Work this out further

    \section{Quantizing the electromagnetic field}
        \subsection{Dipole moment}
        \subsection{Energy spectrum}

    \section{Laser field}
        \subsection{Polarization}
        \subsection{Envelope}

    \section{Physical units}
        \subsection{Atomic units}
